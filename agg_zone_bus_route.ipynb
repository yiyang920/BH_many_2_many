{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "os.environ[\"PROJ_LIB\"] = r\"C:\\\\Users\\\\SQwan\\\\miniconda3\\\\Library\\\\share\"\n",
    "import pickle\n",
    "import googlemaps\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import csv\n",
    "import glob\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from python_tsp.exact import solve_tsp_dynamic_programming\n",
    "from python_tsp.distances import great_circle_distance_matrix\n",
    "from shapely.geometry import Point, shape, Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import shapely.speedups\n",
    "\n",
    "shapely.speedups.enable()\n",
    "\n",
    "if not os.path.exists(r\"Data\"):\n",
    "    os.makedirs(r\"Data\")\n",
    "\n",
    "if not os.path.exists(r\"Data\\temp\"):\n",
    "    os.makedirs(r\"Data\\temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blue, red, and yellow route stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_station = [Point(42.116034, -86.452483),\n",
    "                Point(42.115074, -86.465348),\n",
    "                Point(42.110256, -86.463736),\n",
    "                Point(42.110254, -86.457768),\n",
    "                Point(42.101634, -86.448961),\n",
    "                Point(42.101646, -86.441657),\n",
    "                Point(42.102544, -86.436052),\n",
    "                Point(42.088709, -86.437108),\n",
    "                Point(42.084822, -86.437156),\n",
    "                Point(42.080667, -86.434759),\n",
    "                Point(42.085583, -86.433805),\n",
    "                Point(42.085637, -86.424232),\n",
    "                Point(42.082548, -86.421979),\n",
    "                Point(42.082242, -86.418849),\n",
    "                Point(42.077808, -86.424668),\n",
    "                Point(42.102544, -86.436052),\n",
    "                Point(42.107206, -86.446024),\n",
    "                Point(42.109733, -86.447242),\n",
    "                Point(42.116034, -86.452483),\n",
    "                ]\n",
    "blue_station = [Point(p.y, p.x) for p in blue_station]\n",
    "\n",
    "red_station = [Point(42.101646,\t-86.441657),\n",
    "               Point(42.101634,\t-86.448961),\n",
    "               Point(42.116034,\t-86.452483),\n",
    "               Point(42.115074,\t-86.465348),\n",
    "               Point(42.111264,\t-86.481872),\n",
    "               Point(42.088810,\t-86.478394),\n",
    "               Point(42.084126,\t-86.486379),\n",
    "               Point(42.079074,\t-86.493490),\n",
    "               Point(42.033439,\t-86.513542),\n",
    "               Point(42.026502,\t-86.516012),\n",
    "               Point(42.086425,\t-86.440537),\n",
    "               Point(42.101646,\t-86.441657),\n",
    "               ]\n",
    "red_station = [Point(p.y, p.x) for p in red_station]\n",
    "\n",
    "yellow_station = [Point(42.118494913335645, -86.45082973186932),\n",
    "                  Point(42.13082775201815, -86.4538851865351),\n",
    "                  Point(42.13268958444188, -86.45128880811971),\n",
    "                  Point(42.124573800847095, -86.4460383743168),\n",
    "                  Point(42.121903066372475, -86.4390957589761),\n",
    "                  Point(42.116026992072754, -86.4296080933503),\n",
    "                  Point(42.11587877166418, -86.43641202669362),\n",
    "                  Point(42.112791181420455, -86.4407060644722),\n",
    "                  Point(42.10241413329736, -86.43602474092258),\n",
    "                  Point(42.10241413, -86.43602474),\n",
    "                  Point(42.11279118, -86.44070606),\n",
    "                  Point(42.11587877, -86.43641203),\n",
    "                  Point(42.11602699, -86.42960809),\n",
    "                  Point(42.12190307, -86.43909576),\n",
    "                  Point(42.1245738,\t-86.44603837),\n",
    "                  Point(42.13268958, -86.45128881),\n",
    "                  Point(42.13082775\t, -86.45388519),\n",
    "                  Point(42.11849491, -86.45082973),\n",
    "                  ]\n",
    "yellow_station = [Point(p.y, p.x) for p in yellow_station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_point(point, geoseries):\n",
    "    \"\"\"\n",
    "    Checker function which determines if a coordinate is within \n",
    "    the geoseries and return the zone id where the point is \n",
    "    located\n",
    "    \"\"\"\n",
    "    idx_list = geoseries.index[geoseries.geometry.contains(point)].tolist()\n",
    "    return idx_list[0] if len(idx_list) >= 1 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(r\"Data\\shapefile\\zone_id_agg.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_station_id = [gdf.loc[locate_point(p, gdf), \"zone_id\"] for p in blue_station]\n",
    "blue_station_id = [\n",
    "    v\n",
    "    for i, v in enumerate(blue_station_id)\n",
    "    if i < len(blue_station_id) - 1\n",
    "    if v != blue_station_id[i + 1]\n",
    "]\n",
    "\n",
    "blue_station_id += [gdf.loc[locate_point(blue_station[-1], gdf), \"zone_id\"]]\n",
    "\n",
    "red_station_id = [gdf.loc[locate_point(p, gdf), \"zone_id\"] for p in red_station]\n",
    "red_station_id = [\n",
    "    v\n",
    "    for i, v in enumerate(red_station_id)\n",
    "    if i < len(red_station_id) - 1\n",
    "    if v != red_station_id[i + 1]\n",
    "]\n",
    "\n",
    "red_station_id += [gdf.loc[locate_point(red_station[-1], gdf), \"zone_id\"]]\n",
    "\n",
    "yellow_station_id = [gdf.loc[locate_point(p, gdf), \"zone_id\"] for p in yellow_station]\n",
    "yellow_station_id = [\n",
    "    v\n",
    "    for i, v in enumerate(yellow_station_id)\n",
    "    if i < len(yellow_station_id) - 1\n",
    "    if v != yellow_station_id[i + 1]\n",
    "]\n",
    "\n",
    "yellow_station_id += [gdf.loc[locate_point(yellow_station[-1], gdf), \"zone_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load neighbor nodes information\n",
    "ctr_info = pickle.load(open(r\"Data\\temp\\Station_agg.p\", \"rb\"))\n",
    "# graph with edge cost as shortest travel time\n",
    "G_t = pickle.load(open(r\"Data\\temp\\G_t_agg.p\", \"rb\"))\n",
    "\n",
    "s_blue = list()\n",
    "s_blue.append(blue_station_id[0])\n",
    "for previous, current in zip(blue_station_id, blue_station_id[1:]):\n",
    "    if current in ctr_info[previous][\"neighbours\"]:\n",
    "        s_blue.append(current)\n",
    "    else:\n",
    "        sp = nx.shortest_path(G_t, source=previous, target=current, weight=\"weight\")\n",
    "        s_blue += sp[1:]\n",
    "\n",
    "s_red = list()\n",
    "s_red.append(red_station_id[0])\n",
    "for previous, current in zip(red_station_id, red_station_id[1:]):\n",
    "    if current in ctr_info[previous][\"neighbours\"]:\n",
    "        s_red.append(current)\n",
    "    else:\n",
    "        sp = nx.shortest_path(G_t, source=previous, target=current, weight=\"weight\")\n",
    "        s_red += sp[1:]\n",
    "\n",
    "s_yellow = list()\n",
    "s_yellow.append(yellow_station_id[0])\n",
    "for previous, current in zip(yellow_station_id, yellow_station_id[1:]):\n",
    "    if current in ctr_info[previous][\"neighbours\"]:\n",
    "        s_yellow.append(current)\n",
    "    else:\n",
    "        sp = nx.shortest_path(G_t, source=previous, target=current, weight=\"weight\")\n",
    "        s_yellow += sp[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get bus schedule time based on tau matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph with edge cost as shortest travel time\n",
    "G_t = pickle.load(open(r\"Data\\temp\\G_t_agg.p\", \"rb\"))\n",
    "\n",
    "S = 39  # number of zones\n",
    "DELTA_t = 1  # x min\n",
    "tau = np.zeros((S, S))\n",
    "tau2 = np.zeros((S, S))\n",
    "# round travel time to integer\n",
    "for _, _, d in G_t.edges(data=True):\n",
    "    d[\"weight\"] = np.rint(d[\"weight\"])\n",
    "\n",
    "for i in range(S):\n",
    "    for j in range(S):\n",
    "        if i == j:\n",
    "            tau[i, j] = 0\n",
    "            tau2[i, j] = 1\n",
    "        else:\n",
    "            tau[i, j] = (\n",
    "                nx.shortest_path_length(G_t, source=i, target=j, weight=\"weight\")\n",
    "                // DELTA_t\n",
    "            )\n",
    "            tau2[i, j] = tau[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_blue_1 = np.cumsum(\n",
    "    [0]\n",
    "    + [\n",
    "        tau[s_blue[i], s_blue[i + 1]]\n",
    "        if s_blue[i] != s_blue[i + 1]\n",
    "        else 1\n",
    "        for i in range(len(s_blue) - 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rotate the blue bus station list with 30 mins\n",
    "idx = np.where(sch_blue_1 >= 30)[0][0]\n",
    "s_blue_2 = s_blue[-idx:] + s_blue[:-idx]\n",
    "\n",
    "sch_blue_2 = np.cumsum(\n",
    "    [0]\n",
    "    + [\n",
    "        tau[s_blue_2[i], s_blue_2[i + 1]]\n",
    "        if s_blue_2[i] != s_blue_2[i + 1]\n",
    "        else 1\n",
    "        for i in range(len(s_blue_2) - 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "sch_red_1 = np.cumsum(\n",
    "    [0]\n",
    "    + [\n",
    "        tau[s_red[i], s_red[i + 1]]\n",
    "        if s_red[i] != s_red[i + 1]\n",
    "        else 1\n",
    "        for i in range(len(s_red) - 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "sch_yellow_1 = np.cumsum(\n",
    "    [0]\n",
    "    + [\n",
    "        tau[s_yellow[i], s_yellow[i + 1]]\n",
    "        if s_yellow[i] != s_yellow[i + 1]\n",
    "        else 1\n",
    "        for i in range(len(s_yellow) - 1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_fr_1 = {\"t\": sch_blue_1, \"s\": s_blue * 1}\n",
    "blue_fr_2 = {\"t\": sch_blue_2, \"s\": s_blue_2 * 1}\n",
    "\n",
    "df_blue_fr_1 = pd.DataFrame.from_dict(blue_fr_1)\n",
    "df_blue_fr_2 = pd.DataFrame.from_dict(blue_fr_2)\n",
    "\n",
    "red_fr_1 = {\"t\": sch_red_1, \"s\": s_red * 1}\n",
    "\n",
    "df_red_fr_1 = pd.DataFrame.from_dict(red_fr_1)\n",
    "\n",
    "yellow_fr_1 = {\"t\": sch_yellow_1, \"s\": s_yellow * 1}\n",
    "\n",
    "df_yellow_fr_1 = pd.DataFrame.from_dict(yellow_fr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blue_fr_1.to_csv(r\"many2many_data\\blue_fr_1_agg.csv\", index=False)\n",
    "df_blue_fr_2.to_csv(r\"many2many_data\\blue_fr_2_agg.csv\", index=False)\n",
    "df_red_fr_1.to_csv(r\"many2many_data\\red_fr_1_agg.csv\", index=False)\n",
    "df_yellow_fr_1.to_csv(r\"many2many_data\\yellow_fr_1_agg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zone Disaggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_2_disagg_id = pickle.load(open(r\"Data\\agg_2_disagg_id.p\", \"rb\"))\n",
    "disagg_2_agg_id = pickle.load(open(r\"Data\\disagg_2_agg_id.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_file_path = r\"E:\\Codes\\BH_data_preprocess_and_DP\\test_data\\result\\3_28_2021\\\\\"\n",
    "\n",
    "route_dict = {}\n",
    "\n",
    "for i, f in enumerate(glob.glob(route_file_path + \"route_*_agg.csv\")):\n",
    "    route_dict[i] = pd.read_csv(f, encoding=\"utf-8\")\n",
    "    \n",
    "N_route = len(route_dict) # number of route\n",
    "\n",
    "pth_dict_agg = {}\n",
    "for k, route in route_dict.items():\n",
    "    pth_dict_agg[k] = list(set((route[\"s1\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_dict_temp = {}\n",
    "for k, pth in pth_dict_agg.items():\n",
    "    pth_dict_temp[k] = [agg_2_disagg_id[s] for s in pth]\n",
    "\n",
    "pth_dict = {}    \n",
    "for k, pth in pth_dict_temp.items():\n",
    "    pth_dict[k] = list()\n",
    "    for lst in pth:\n",
    "        pth_dict[k] += lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve the Open TSP Problem\n",
    "After solving the aggregated many-to-many problem, solve the disaggregated sub-problem as an open TSP problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_info = pickle.load(open(r\"Data\\temp\\Station.p\", \"rb\"))\n",
    "c_dict = {\n",
    "    k: [ctr_info[zone][\"lat_lon\"] for zone in zone_lst]\n",
    "    for k, zone_lst in pth_dict.items()\n",
    "} # centroid coordinates of zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph with edge cost as shortest travel time\n",
    "G_t = pickle.load(open(r\"Data\\temp\\G_t.p\", \"rb\"))\n",
    "\n",
    "S = 69  # number of zones\n",
    "DELTA_t = 1  # x min\n",
    "tau = np.zeros((S, S))\n",
    "tau2 = np.zeros((S, S))\n",
    "# round travel time to integer\n",
    "for _, _, d in G_t.edges(data=True):\n",
    "    d[\"weight\"] = np.rint(d[\"weight\"])\n",
    "\n",
    "for i in range(S):\n",
    "    for j in range(S):\n",
    "        if i == j:\n",
    "            tau[i, j] = 0\n",
    "            tau2[i, j] = 1\n",
    "        else:\n",
    "            tau[i, j] = (\n",
    "                nx.shortest_path_length(G_t, source=i, target=j, weight=\"weight\")\n",
    "                // DELTA_t\n",
    "            )\n",
    "            tau2[i, j] = tau[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = np.zeros((len(c_dict[4]), len(c_dict[4])))\n",
    "for i in range(len(c_dict[4])):\n",
    "    for j in range(len(c_dict[4])):\n",
    "        distance_matrix[i, j] = tau[pth_dict[4][i], pth_dict[4][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 7, 5, 6, 8, 17, 18, 16, 14, 15, 13, 12, 11, 4, 3, 1, 2, 10, 9]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance_matrix = great_circle_distance_matrix(c_dict[4]) # only the 5-th route is optimized\n",
    "permutation, distance = solve_tsp_dynamic_programming(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if all pair of successive zones are neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_id = [pth_dict[4][i] for i in permutation]\n",
    "# Load neighbor nodes information\n",
    "ctr_info = pickle.load(open(r\"Data\\temp\\Station.p\", \"rb\"))\n",
    "# graph with edge cost as shortest travel time\n",
    "G_t = pickle.load(open(r\"Data\\temp\\G_t.p\", \"rb\"))\n",
    "\n",
    "s = list()\n",
    "s.append(route_id[0])\n",
    "for previous, current in zip(route_id, route_id[1:]):\n",
    "    if current in ctr_info[previous][\"neighbours\"]:\n",
    "        s.append(current)\n",
    "    else:\n",
    "        sp = nx.shortest_path(G_t, source=previous, target=current, weight=\"weight\")\n",
    "        s += sp[1:]\n",
    "\n",
    "# make sure the bus back to the depot\n",
    "s.append(s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bus schedule time based on tau matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph with edge cost as shortest travel time\n",
    "G_t = pickle.load(open(r\"Data\\temp\\G_t.p\", \"rb\"))\n",
    "\n",
    "S = 69  # number of zones\n",
    "DELTA_t = 1  # x min\n",
    "tau = np.zeros((S, S))\n",
    "tau2 = np.zeros((S, S))\n",
    "# round travel time to integer\n",
    "for _, _, d in G_t.edges(data=True):\n",
    "    d[\"weight\"] = np.rint(d[\"weight\"])\n",
    "\n",
    "for i in range(S):\n",
    "    for j in range(S):\n",
    "        if i == j:\n",
    "            tau[i, j] = 0\n",
    "            tau2[i, j] = 1\n",
    "        else:\n",
    "            tau[i, j] = (\n",
    "                nx.shortest_path_length(G_t, source=i, target=j, weight=\"weight\")\n",
    "                // DELTA_t\n",
    "            )\n",
    "            tau2[i, j] = tau[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = np.cumsum(\n",
    "    [0] + [tau[s[i], s[i + 1]] if s[i] != s[i + 1] else 1 for i in range(len(s) - 1)]\n",
    ")\n",
    "fr = {\"t\": sch, \"s\": s * 1}\n",
    "\n",
    "df_fr = pd.DataFrame.from_dict(fr)\n",
    "df_fr.to_csv(r\"many2many_output\\fr_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sch = pd.DataFrame()\n",
    "df_sch[\"t1\"], df_sch[\"t2\"] = fr[\"t\"][:-1], fr[\"t\"][1:]\n",
    "df_sch[\"s1\"], df_sch[\"s2\"] = fr[\"s\"][:-1], fr[\"s\"][1:]\n",
    "df_sch.to_csv(r\"many2many_output\\sch_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open TSP Problem模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = np.array([],)  # centroid coordinates of zones\n",
    "distance_matrix = great_circle_distance_matrix(sources)\n",
    "# set all elements of the first column of the distance matrix to zero\n",
    "distance_matrix[:, 0] = 0\n",
    "permutation, distance = solve_tsp_dynamic_programming(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
